# =============================================================================
# INTERACTIVE VISUALIZATION FRAMEWORK FOR JOYCE SIMILE ANALYSIS
# Advanced Data Visualization: Network Graphs, Heatmaps, Bee Swarms
# Confidence Intervals, Wilson Scores, Topic Modeling, Joyce vs BNC Comparison
# =============================================================================

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo
import networkx as nx
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
import warnings
warnings.filterwarnings('ignore')

print("INTERACTIVE VISUALIZATION FRAMEWORK FOR JOYCE SIMILE ANALYSIS")
print("=" * 65)
print("Visualization Components:")
print("- Interactive Network Graphs (Category-Comparator Relationships)")
print("- Wilson Score Confidence Intervals")
print("- Topic Modeling Visualizations")
print("- Bee Swarm Plots (Token Distribution)")
print("- Multi-dimensional Heatmaps")
print("- Joyce vs BNC Comparative Analysis")
print("- Interactive Dashboard with All Visualizations")
print("=" * 65)

class JoyceSimileVisualizer:
    """
    Advanced visualization framework for Joyce simile research.
    
    This class creates interactive visualizations to explore patterns in
    simile usage across manual annotations, computational extractions,
    and BNC baseline corpus, with focus on Joyce's stylistic innovations.
    """
    
    def __init__(self, data_path="comprehensive_linguistic_analysis.csv"):
        
        # 2. Structural pattern comparison (Pre/Post ratio)
        joyce_valid = joyce_data[joyce_data['Pre_Post_Ratio'].notna()]
        bnc_valid = bnc_data[bnc_data['Pre_Post_Ratio'].notna()]
        
        if len(joyce_valid) > 0 and len(bnc_valid) > 0:
            fig.add_trace(
                go.Scatter(
                    x=joyce_valid['Pre_Comparator_Tokens'],
                    y=joyce_valid['Post_Comparator_Tokens'],
                    mode='markers',
                    name="Joyce",
                    marker=dict(color='#FF6B6B', size=6, opacity=0.6),
                    hovertemplate="<b>Joyce</b><br>" +
                                 "Pre-tokens: %{x}<br>" +
                                 "Post-tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Scatter(
                    x=bnc_valid['Pre_Comparator_Tokens'],
                    y=bnc_valid['Post_Comparator_Tokens'],
                    mode='markers',
                    name="BNC",
                    marker=dict(color='#45B7D1', size=6, opacity=0.6),
                    hovertemplate="<b>BNC</b><br>" +
                                 "Pre-tokens: %{x}<br>" +
                                 "Post-tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=1, col=2
            )
        
        # 3. Sentiment comparison
        joyce_sentiment = joyce_data[joyce_data['Sentiment_Polarity'].notna()]
        bnc_sentiment = bnc_data[bnc_data['Sentiment_Polarity'].notna()]
        
        if len(joyce_sentiment) > 0:
            fig.add_trace(
                go.Violin(
                    y=joyce_sentiment['Sentiment_Polarity'],
                    name="Joyce Sentiment",
                    side="negative",
                    line_color='#FF6B6B',
                    hovertemplate="<b>Joyce</b><br>" +
                                 "Sentiment: %{y:.3f}<br>" +
                                 "<extra></extra>"
                ),
                row=2, col=1
            )
        
        if len(bnc_sentiment) > 0:
            fig.add_trace(
                go.Violin(
                    y=bnc_sentiment['Sentiment_Polarity'],
                    name="BNC Sentiment",
                    side="positive",
                    line_color='#45B7D1',
                    hovertemplate="<b>BNC</b><br>" +
                                 "Sentiment: %{y:.3f}<br>" +
                                 "<extra></extra>"
                ),
                row=2, col=1
            )
        
        # 4. Comparator usage comparison
        joyce_comps = joyce_data['Comparator_Type'].value_counts()
        bnc_comps = bnc_data['Comparator_Type'].value_counts()
        
        # Get top comparators
        all_comps = sorted(set(joyce_comps.index) | set(bnc_comps.index))[:8]
        
        joyce_comp_counts = [joyce_comps.get(comp, 0) for comp in all_comps]
        bnc_comp_counts = [bnc_comps.get(comp, 0) for comp in all_comps]
        
        fig.add_trace(
            go.Bar(
                x=all_comps,
                y=joyce_comp_counts,
                name="Joyce Comparators",
                marker_color='#FF6B6B',
                showlegend=False,
                hovertemplate="<b>Joyce</b><br>" +
                             "Comparator: %{x}<br>" +
                             "Count: %{y}<br>" +
                             "<extra></extra>"
            ),
            row=2, col=2
        )
        
        fig.add_trace(
            go.Bar(
                x=all_comps,
                y=bnc_comp_counts,
                name="BNC Comparators",
                marker_color='#45B7D1',
                showlegend=False,
                hovertemplate="<b>BNC</b><br>" +
                             "Comparator: %{x}<br>" +
                             "Count: %{y}<br>" +
                             "<extra></extra>"
            ),
            row=2, col=2
        )
        
        # 5. Token length distribution comparison
        joyce_tokens = joyce_data[joyce_data['Total_Tokens'].notna()]
        bnc_tokens = bnc_data[bnc_data['Total_Tokens'].notna()]
        
        if len(joyce_tokens) > 0:
            fig.add_trace(
                go.Box(
                    y=joyce_tokens['Total_Tokens'],
                    name="Joyce Length",
                    marker_color='#FF6B6B',
                    boxpoints='outliers',
                    showlegend=False,
                    hovertemplate="<b>Joyce</b><br>" +
                                 "Total tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=3, col=1
            )
        
        if len(bnc_tokens) > 0:
            fig.add_trace(
                go.Box(
                    y=bnc_tokens['Total_Tokens'],
                    name="BNC Length",
                    marker_color='#45B7D1',
                    boxpoints='outliers',
                    showlegend=False,
                    hovertemplate="<b>BNC</b><br>" +
                                 "Total tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=3, col=1
            )
        
        # 6. Statistical summary table
        # Calculate key statistics
        stats_data = []
        
        # Token statistics
        if len(joyce_tokens) > 0 and len(bnc_tokens) > 0:
            joyce_mean_tokens = joyce_tokens['Total_Tokens'].mean()
            bnc_mean_tokens = bnc_tokens['Total_Tokens'].mean()
            
            # T-test for token lengths
            from scipy.stats import ttest_ind
            t_stat, p_val = ttest_ind(joyce_tokens['Total_Tokens'], bnc_tokens['Total_Tokens'])
            
            stats_data.extend([
                ['Metric', 'Joyce', 'BNC', 'Significance'],
                ['Avg Token Length', f'{joyce_mean_tokens:.2f}', f'{bnc_mean_tokens:.2f}', f'p={p_val:.3f}'],
            ])
        
        # Sentiment statistics
        if len(joyce_sentiment) > 0 and len(bnc_sentiment) > 0:
            joyce_mean_sent = joyce_sentiment['Sentiment_Polarity'].mean()
            bnc_mean_sent = bnc_sentiment['Sentiment_Polarity'].mean()
            
            t_stat_sent, p_val_sent = ttest_ind(
                joyce_sentiment['Sentiment_Polarity'], 
                bnc_sentiment['Sentiment_Polarity']
            )
            
            stats_data.append([
                'Avg Sentiment', f'{joyce_mean_sent:.3f}', f'{bnc_mean_sent:.3f}', f'p={p_val_sent:.3f}'
            ])
        
        # Ratio statistics
        if len(joyce_valid) > 0 and len(bnc_valid) > 0:
            joyce_mean_ratio = joyce_valid['Pre_Post_Ratio'].mean()
            bnc_mean_ratio = bnc_valid['Pre_Post_Ratio'].mean()
            
            t_stat_ratio, p_val_ratio = ttest_ind(
                joyce_valid['Pre_Post_Ratio'], 
                bnc_valid['Pre_Post_Ratio']
            )
            
            stats_data.append([
                'Avg Pre/Post Ratio', f'{joyce_mean_ratio:.2f}', f'{bnc_mean_ratio:.2f}', f'p={p_val_ratio:.3f}'
            ])
        
        if stats_data:
            fig.add_trace(
                go.Table(
                    header=dict(
                        values=stats_data[0],
                        fill_color='lightgray',
                        align='center',
                        font=dict(size=12, color='black')
                    ),
                    cells=dict(
                        values=list(zip(*stats_data[1:])),
                        fill_color='white',
                        align='center',
                        font=dict(size=11)
                    )
                ),
                row=3, col=2
            )
        
        # Update layout
        fig.update_layout(
            title={
                'text': "Comprehensive Joyce vs BNC Comparison Analysis",
                'x': 0.5,
                'font': {'size': 18}
            },
            height=1000,
            showlegend=True
        )
        
        # Update axis labels
        fig.update_xaxes(title_text="Categories", row=1, col=1)
        fig.update_yaxes(title_text="Proportion", row=1, col=1)
        
        fig.update_xaxes(title_text="Pre-Comparator Tokens", row=1, col=2)
        fig.update_yaxes(title_text="Post-Comparator Tokens", row=1, col=2)
        
        fig.update_yaxes(title_text="Sentiment Polarity", row=2, col=1)
        
        fig.update_xaxes(title_text="Comparator Types", row=2, col=2)
        fig.update_yaxes(title_text="Count", row=2, col=2)
        
        fig.update_yaxes(title_text="Total Tokens", row=3, col=1)
        
        self.figures['joyce_vs_bnc'] = fig
        print("Joyce vs BNC comparison visualization created successfully")
        return fig
    
    def create_interactive_dashboard(self):
        """
        Create comprehensive interactive dashboard combining all visualizations.
        """
        print("\nCREATING INTERACTIVE DASHBOARD")
        print("-" * 32)
        
        # Create dashboard HTML with all figures
        dashboard_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Joyce Simile Analysis - Interactive Dashboard</title>
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .dashboard-header {{ text-align: center; margin-bottom: 30px; }}
                .visualization-section {{ margin-bottom: 40px; }}
                .section-title {{ font-size: 24px; font-weight: bold; margin-bottom: 15px; color: #333; }}
                .description {{ font-size: 14px; color: #666; margin-bottom: 20px; }}
                .plot-container {{ width: 100%; height: 600px; margin-bottom: 20px; }}
                .stats-summary {{ background-color: #f8f9fa; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
            </style>
        </head>
        <body>
            <div class="dashboard-header">
                <h1>Interactive Dashboard: Joyce Simile Analysis</h1>
                <p>Computational Literary Analysis of Simile Patterns in Dubliners</p>
                <div class="stats-summary">
                    <h3>Dataset Overview</h3>
                    <p><strong>Total Instances:</strong> {len(self.df)} similes analyzed</p>
                    <p><strong>Manual Annotations:</strong> {len(self.df[self.df['Dataset'] == 'manual'])} instances</p>
                    <p><strong>Computational Extraction:</strong> {len(self.df[self.df['Dataset'] == 'computational'])} instances</p>
                    <p><strong>BNC Baseline:</strong> {len(self.df[self.df['Dataset'] == 'bnc'])} instances</p>
                </div>
            </div>
        """
        
        # Add each visualization section
        visualization_sections = [
            {
                'title': 'Network Graph Analysis',
                'description': 'Interactive network showing relationships between simile categories, comparators, and datasets.',
                'figure_key': 'network_graph'
            },
            {
                'title': 'Wilson Score Confidence Intervals',
                'description': 'Statistical confidence intervals for category proportions across datasets.',
                'figure_key': 'wilson_intervals'
            },
            {
                'title': 'Topic Modeling Visualization',
                'description': 'Thematic analysis revealing semantic fields and patterns in simile usage.',
                'figure_key': 'topic_modeling'
            },
            {
                'title': 'Token Distribution Analysis',
                'description': 'Bee swarm plots showing structural patterns in pre/post-comparator token distributions.',
                'figure_key': 'bee_swarm'
            },
            {
                'title': 'Multi-Dimensional Heatmap',
                'description': 'Comprehensive heatmap displaying linguistic features across datasets and categories.',
                'figure_key': 'heatmap'
            },
            {
                'title': 'Joyce vs BNC Comparison',
                'description': 'Detailed comparison between Joyce\'s simile patterns and BNC baseline corpus.',
                'figure_key': 'joyce_vs_bnc'
            }
        ]
        
        for i, section in enumerate(visualization_sections):
            if section['figure_key'] in self.figures:
                dashboard_html += f"""
                <div class="visualization-section">
                    <div class="section-title">{section['title']}</div>
                    <div class="description">{section['description']}</div>
                    <div id="plot{i}" class="plot-container"></div>
                </div>
                """
        
        dashboard_html += """
            <script>
        """
        
        # Add JavaScript to render each plot
        for i, section in enumerate(visualization_sections):
            if section['figure_key'] in self.figures:
                fig_json = self.figures[section['figure_key']].to_json()
                dashboard_html += f"""
                var fig{i} = {fig_json};
                Plotly.newPlot('plot{i}', fig{i}.data, fig{i}.layout, {{responsive: true}});
                """
        
        dashboard_html += """
            </script>
        </body>
        </html>
        """
        
        # Save dashboard
        with open('joyce_simile_dashboard.html', 'w', encoding='utf-8') as f:
            f.write(dashboard_html)
        
        print("Interactive dashboard saved as 'joyce_simile_dashboard.html'")
        return dashboard_html
    
    def save_all_visualizations(self):
        """
        Save all individual visualizations as HTML files.
        """
        print("\nSAVING ALL VISUALIZATIONS")
        print("-" * 27)
        
        for figure_name, figure in self.figures.items():
            filename = f"joyce_simile_{figure_name}.html"
            figure.write_html(filename)
            print(f"Saved: {filename}")
        
        print(f"Total visualizations saved: {len(self.figures)}")
    
    def generate_visualization_report(self):
        """
        Generate detailed report of visualization findings.
        """
        print("\nVISUALIZATION ANALYSIS REPORT")
        print("=" * 31)
        
        # Dataset statistics
        print("\nDATASET STATISTICS:")
        for dataset in self.df['Dataset'].unique():
            dataset_df = self.df[self.df['Dataset'] == dataset]
            print(f"{dataset.upper()} Dataset:")
            print(f"  Total instances: {len(dataset_df)}")
            print(f"  Unique categories: {dataset_df['Category_Framework'].nunique()}")
            print(f"  Most common comparator: {dataset_df['Comparator_Type'].mode().iloc[0] if len(dataset_df) > 0 else 'N/A'}")
        
        # Category analysis
        print(f"\nCATEGORY FRAMEWORK ANALYSIS:")
        category_counts = self.df['Category_Framework'].value_counts()
        total_instances = len(self.df)
        
        for category, count in category_counts.items():
            percentage = (count / total_instances) * 100
            print(f"{category}: {count} instances ({percentage:.1f}%)")
        
        # Joyce innovation analysis
        joycean_categories = ['Joycean_Silent', 'Joycean_Quasi', 'Joycean_Framed', 'Joycean_Quasi_Fuzzy']
        joyce_data = self.df[self.df['Dataset'].isin(['manual', 'computational'])]
        joycean_instances = joyce_data[joyce_data['Category_Framework'].isin(joycean_categories)]
        
        if len(joyce_data) > 0:
            innovation_ratio = len(joycean_instances) / len(joyce_data) * 100
            print(f"\nJOYCEAN INNOVATION ANALYSIS:")
            print(f"Joyce instances with Joycean categories: {len(joycean_instances)}/{len(joyce_data)} ({innovation_ratio:.1f}%)")
        
        # Statistical significance summary
        if len(self.df[self.df['Dataset'] == 'bnc']) > 0 and len(joyce_data) > 0:
            print(f"\nSTATISTICAL FINDINGS:")
            print(f"Joyce similes analyzed: {len(joyce_data)}")
            print(f"BNC baseline similes: {len(self.df[self.df['Dataset'] == 'bnc'])}")
            print(f"Statistical comparison available in visualization outputs")
        
        print(f"\nVISUALIZATION COMPONENTS GENERATED:")
        for figure_name in self.figures.keys():
            print(f"  {figure_name.replace('_', ' ').title()}")
        
        print(f"\nREADY FOR THESIS INTEGRATION:")
        print(f"All visualizations are interactive and publication-ready")
        print(f"Dashboard provides comprehensive overview for presentation")

def execute_complete_visualization_pipeline():
    """
    Execute the complete visualization pipeline for Joyce simile analysis.
    """
    print("EXECUTING COMPLETE VISUALIZATION PIPELINE")
    print("=" * 43)
    
    # Initialize visualizer
    visualizer = JoyceSimileVisualizer("comprehensive_linguistic_analysis.csv")
    
    if visualizer.df is None:
        print("Error: Could not load data for visualization")
        return None
    
    # Create all visualizations
    print("\nCreating all visualization components...")
    
    # 1. Network graph
    visualizer.create_network_graph()
    
    # 2. Wilson score confidence intervals
    visualizer.create_wilson_score_confidence_intervals()
    
    # 3. Topic modeling visualization
    visualizer.create_topic_modeling_visualization()
    
    # 4. Bee swarm plots
    visualizer.create_bee_swarm_plots()
    
    # 5. Comprehensive heatmap
    visualizer.create_comprehensive_heatmap()
    
    # 6. Joyce vs BNC comparison
    visualizer.create_joyce_vs_bnc_comparison()
    
    # 7. Interactive dashboard
    visualizer.create_interactive_dashboard()
    
    # 8. Save all visualizations
    visualizer.save_all_visualizations()
    
    # 9. Generate report
    visualizer.generate_visualization_report()
    
    print(f"\nVISUALIZATION PIPELINE COMPLETED")
    print("=" * 32)
    print("Generated Files:")
    print("- joyce_simile_dashboard.html (Complete interactive dashboard)")
    print("- Individual visualization HTML files")
    print("- All visualizations are interactive and publication-ready")
    print("\nThesis Integration:")
    print("- Use dashboard for comprehensive presentation")
    print("- Individual plots for specific analysis sections")
    print("- All visualizations demonstrate Joyce's stylistic innovations")
    
    return visualizer

# Execute the complete visualization pipeline
visualizer = execute_complete_visualization_pipeline()

print("\nINTERACTIVE VISUALIZATION FRAMEWORK COMPLETED")
print("Ready for thesis integration and academic presentation")"""
        Initialize the visualization framework.
        
        Args:
            data_path (str): Path to comprehensive analysis results CSV
        """
        self.data_path = data_path
        self.df = None
        self.figures = {}
        self.load_data()
        
    def load_data(self):
        """Load and prepare data for visualization."""
        print("\nLOADING COMPREHENSIVE ANALYSIS DATA")
        print("-" * 37)
        
        try:
            self.df = pd.read_csv(self.data_path)
            print(f"Data loaded successfully: {len(self.df)} instances")
            print(f"Columns available: {len(self.df.columns)}")
            
            # Clean and prepare data
            self.df['Dataset'] = self.df['Original_Dataset'].fillna(self.df['Dataset_Source'])
            self.df = self.df.dropna(subset=['Category_Framework'])
            
            print(f"Data prepared for visualization: {len(self.df)} instances")
            
        except Exception as e:
            print(f"Error loading data: {e}")
            return None
    
    def create_network_graph(self):
        """
        Create interactive network graph showing relationships between 
        categories, comparators, and datasets.
        """
        print("\nCREATING INTERACTIVE NETWORK GRAPH")
        print("-" * 36)
        
        # Create network graph
        G = nx.Graph()
        
        # Add nodes and edges based on relationships
        edge_weights = {}
        
        for _, row in self.df.iterrows():
            category = f"Cat_{row['Category_Framework']}"
            comparator = f"Comp_{row['Comparator_Type']}"
            dataset = f"Data_{row['Dataset']}"
            
            # Add nodes
            G.add_node(category, type='category', size=10)
            G.add_node(comparator, type='comparator', size=8)
            G.add_node(dataset, type='dataset', size=12)
            
            # Add edges with weights
            edges = [(category, comparator), (category, dataset), (comparator, dataset)]
            for edge in edges:
                if edge in edge_weights:
                    edge_weights[edge] += 1
                else:
                    edge_weights[edge] = 1
        
        # Add weighted edges to graph
        for (node1, node2), weight in edge_weights.items():
            G.add_edge(node1, node2, weight=weight)
        
        # Calculate layout
        pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
        
        # Prepare traces for Plotly
        edge_x = []
        edge_y = []
        edge_info = []
        
        for edge in G.edges():
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
            weight = G[edge[0]][edge[1]]['weight']
            edge_info.append(f"{edge[0]} â†” {edge[1]}: {weight} connections")
        
        # Create node traces by type
        node_traces = {}
        colors = {'category': '#FF6B6B', 'comparator': '#4ECDC4', 'dataset': '#45B7D1'}
        
        for node_type in ['category', 'comparator', 'dataset']:
            node_x = []
            node_y = []
            node_text = []
            node_info = []
            
            for node in G.nodes():
                if G.nodes[node]['type'] == node_type:
                    x, y = pos[node]
                    node_x.append(x)
                    node_y.append(y)
                    
                    # Clean node name for display
                    display_name = node.replace('Cat_', '').replace('Comp_', '').replace('Data_', '')
                    node_text.append(display_name)
                    
                    # Calculate node degree for size
                    degree = G.degree(node)
                    connections = list(G.neighbors(node))
                    node_info.append(f"{display_name}<br>Connections: {degree}<br>Links: {', '.join([n.replace('Cat_', '').replace('Comp_', '').replace('Data_', '') for n in connections[:3]])}")
            
            node_traces[node_type] = go.Scatter(
                x=node_x, y=node_y,
                mode='markers+text',
                text=node_text,
                textposition="middle center",
                hovertext=node_info,
                hoverinfo='text',
                marker=dict(
                    size=[G.degree(node) * 3 + 10 for node in G.nodes() if G.nodes[node]['type'] == node_type],
                    color=colors[node_type],
                    line=dict(width=2, color='white')
                ),
                name=node_type.title()
            )
        
        # Create figure
        fig = go.Figure()
        
        # Add edges
        fig.add_trace(go.Scatter(
            x=edge_x, y=edge_y,
            line=dict(width=1, color='#888'),
            hoverinfo='none',
            mode='lines',
            showlegend=False
        ))
        
        # Add node traces
        for trace in node_traces.values():
            fig.add_trace(trace)
        
        fig.update_layout(
            title={
                'text': "Interactive Network Graph: Simile Categories, Comparators & Datasets",
                'x': 0.5,
                'font': {'size': 16}
            },
            showlegend=True,
            hovermode='closest',
            margin=dict(b=20, l=5, r=5, t=40),
            annotations=[
                dict(
                    text="Node size indicates connection strength. Hover for details.",
                    showarrow=False,
                    xref="paper", yref="paper",
                    x=0.005, y=-0.002,
                    xanchor='left', yanchor='bottom',
                    font=dict(color='gray', size=12)
                )
            ],
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            plot_bgcolor='white'
        )
        
        self.figures['network_graph'] = fig
        print("Interactive network graph created successfully")
        return fig
    
    def create_wilson_score_confidence_intervals(self):
        """
        Create interactive visualization of Wilson Score confidence intervals
        for category proportions across datasets.
        """
        print("\nCREATING WILSON SCORE CONFIDENCE INTERVALS")
        print("-" * 44)
        
        # Calculate Wilson Score intervals for each dataset
        confidence_level = 0.95
        z_score = stats.norm.ppf((1 + confidence_level) / 2)
        
        interval_data = []
        
        for dataset in self.df['Dataset'].unique():
            dataset_df = self.df[self.df['Dataset'] == dataset]
            category_counts = dataset_df['Category_Framework'].value_counts()
            total = len(dataset_df)
            
            for category, count in category_counts.items():
                p = count / total
                n = total
                
                # Wilson Score Interval calculation
                denominator = 1 + z_score**2 / n
                center = (p + z_score**2 / (2*n)) / denominator
                width = z_score * np.sqrt(p*(1-p)/n + z_score**2/(4*n**2)) / denominator
                
                lower_bound = max(0, center - width)
                upper_bound = min(1, center + width)
                
                interval_data.append({
                    'Dataset': dataset,
                    'Category': category,
                    'Proportion': p,
                    'Lower_CI': lower_bound,
                    'Upper_CI': upper_bound,
                    'Count': count,
                    'Total': total,
                    'Interval_Width': upper_bound - lower_bound
                })
        
        intervals_df = pd.DataFrame(interval_data)
        
        # Create interactive confidence interval plot
        fig = go.Figure()
        
        colors = {'manual': '#FF6B6B', 'computational': '#4ECDC4', 'bnc': '#45B7D1'}
        
        for i, dataset in enumerate(intervals_df['Dataset'].unique()):
            dataset_data = intervals_df[intervals_df['Dataset'] == dataset]
            
            # Sort by proportion for better visualization
            dataset_data = dataset_data.sort_values('Proportion', ascending=True)
            
            y_positions = np.arange(len(dataset_data)) + i * 0.3
            
            # Add confidence intervals
            fig.add_trace(go.Scatter(
                x=dataset_data['Proportion'],
                y=y_positions,
                mode='markers',
                marker=dict(
                    size=12,
                    color=colors.get(dataset, '#666666'),
                    symbol='circle'
                ),
                name=f"{dataset.title()} Proportions",
                hovertemplate="<b>%{text}</b><br>" +
                             "Dataset: " + dataset + "<br>" +
                             "Proportion: %{x:.3f}<br>" +
                             "95% CI: [%{customdata[0]:.3f}, %{customdata[1]:.3f}]<br>" +
                             "Count: %{customdata[2]} / %{customdata[3]}<br>" +
                             "<extra></extra>",
                text=dataset_data['Category'],
                customdata=dataset_data[['Lower_CI', 'Upper_CI', 'Count', 'Total']].values
            ))
            
            # Add confidence interval error bars
            fig.add_trace(go.Scatter(
                x=dataset_data['Lower_CI'],
                y=y_positions,
                mode='markers',
                marker=dict(size=3, color=colors.get(dataset, '#666666'), symbol='line-ew'),
                showlegend=False,
                hoverinfo='skip'
            ))
            
            fig.add_trace(go.Scatter(
                x=dataset_data['Upper_CI'],
                y=y_positions,
                mode='markers',
                marker=dict(size=3, color=colors.get(dataset, '#666666'), symbol='line-ew'),
                showlegend=False,
                hoverinfo='skip'
            ))
            
            # Add horizontal lines for confidence intervals
            for j, row in dataset_data.iterrows():
                fig.add_shape(
                    type="line",
                    x0=row['Lower_CI'], y0=y_positions.iloc[j],
                    x1=row['Upper_CI'], y1=y_positions.iloc[j],
                    line=dict(color=colors.get(dataset, '#666666'), width=2)
                )
        
        # Update layout
        all_categories = intervals_df['Category'].unique()
        fig.update_layout(
            title={
                'text': "Wilson Score Confidence Intervals (95% CI) for Category Proportions",
                'x': 0.5,
                'font': {'size': 16}
            },
            xaxis_title="Proportion",
            yaxis=dict(
                tickvals=np.arange(len(all_categories)),
                ticktext=all_categories,
                title="Simile Categories"
            ),
            hovermode='closest',
            plot_bgcolor='white',
            height=600
        )
        
        self.figures['wilson_intervals'] = fig
        print("Wilson Score confidence intervals visualization created")
        return fig
    
    def create_topic_modeling_visualization(self):
        """
        Create interactive topic modeling visualization with network
        and scatter plot representations.
        """
        print("\nCREATING TOPIC MODELING VISUALIZATION")
        print("-" * 38)
        
        # Filter data with valid topic labels
        topic_df = self.df[
            (self.df['Topic_Label'].notna()) & 
            (self.df['Topic_Label'] != 'Unknown') & 
            (self.df['Topic_Label'] != 'Topic_Analysis_Failed')
        ].copy()
        
        if len(topic_df) == 0:
            print("No valid topic modeling data available")
            return None
        
        # Extract topic information
        topic_df['Topic_Number'] = topic_df['Topic_Label'].str.extract(r'Topic_(\d+):')
        topic_df['Topic_Words'] = topic_df['Topic_Label'].str.extract(r'Topic_\d+: (.+)')
        
        # Create subplot figure
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'Topic Distribution by Dataset',
                'Topic-Dataset Network',
                'Topic Word Clouds (Top Terms)',
                'Topic Sentiment Analysis'
            ),
            specs=[[{"type": "bar"}, {"type": "scatter"}],
                   [{"type": "bar"}, {"type": "scatter"}]]
        )
        
        # 1. Topic distribution by dataset
        topic_dataset_counts = topic_df.groupby(['Dataset', 'Topic_Number']).size().reset_index(name='count')
        
        for dataset in topic_dataset_counts['Dataset'].unique():
            dataset_data = topic_dataset_counts[topic_dataset_counts['Dataset'] == dataset]
            fig.add_trace(
                go.Bar(
                    x=dataset_data['Topic_Number'],
                    y=dataset_data['count'],
                    name=f"{dataset.title()}",
                    hovertemplate="<b>%{fullData.name}</b><br>" +
                                 "Topic: %{x}<br>" +
                                 "Count: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=1, col=1
            )
        
        # 2. Topic network (simplified)
        topic_centers = topic_df.groupby('Topic_Number').agg({
            'Sentiment_Polarity': 'mean',
            'Pre_Post_Ratio': 'mean',
            'Topic_Words': 'first'
        }).reset_index()
        
        fig.add_trace(
            go.Scatter(
                x=topic_centers['Sentiment_Polarity'],
                y=topic_centers['Pre_Post_Ratio'],
                mode='markers+text',
                text=topic_centers['Topic_Number'],
                textposition="middle center",
                marker=dict(
                    size=20,
                    color=topic_centers['Topic_Number'].astype(int),
                    colorscale='Viridis',
                    showscale=True,
                    colorbar=dict(title="Topic Number")
                ),
                hovertemplate="<b>Topic %{text}</b><br>" +
                             "Words: %{customdata}<br>" +
                             "Avg Sentiment: %{x:.3f}<br>" +
                             "Avg Ratio: %{y:.3f}<br>" +
                             "<extra></extra>",
                customdata=topic_centers['Topic_Words'],
                showlegend=False
            ),
            row=1, col=2
        )
        
        # 3. Top terms per topic
        topic_word_data = []
        for _, row in topic_centers.iterrows():
            words = row['Topic_Words'].split(', ')[:5]  # Top 5 words
            for i, word in enumerate(words):
                topic_word_data.append({
                    'Topic': f"Topic_{row['Topic_Number']}",
                    'Word': word,
                    'Position': i + 1
                })
        
        topic_words_df = pd.DataFrame(topic_word_data)
        
        for topic in topic_words_df['Topic'].unique():
            topic_data = topic_words_df[topic_words_df['Topic'] == topic]
            fig.add_trace(
                go.Bar(
                    x=topic_data['Word'],
                    y=[1] * len(topic_data),  # Uniform height
                    name=topic,
                    hovertemplate="<b>%{fullData.name}</b><br>" +
                                 "Word: %{x}<br>" +
                                 "<extra></extra>",
                    showlegend=False
                ),
                row=2, col=1
            )
        
        # 4. Topic sentiment analysis
        if 'Sentiment_Polarity' in topic_df.columns:
            topic_sentiment = topic_df.groupby('Topic_Number')['Sentiment_Polarity'].mean().reset_index()
            
            fig.add_trace(
                go.Scatter(
                    x=topic_sentiment['Topic_Number'],
                    y=topic_sentiment['Sentiment_Polarity'],
                    mode='markers+lines',
                    marker=dict(size=10, color='red'),
                    line=dict(color='red', width=2),
                    hovertemplate="<b>Topic %{x}</b><br>" +
                                 "Avg Sentiment: %{y:.3f}<br>" +
                                 "<extra></extra>",
                    showlegend=False
                ),
                row=2, col=2
            )
        
        # Update layout
        fig.update_layout(
            title={
                'text': "Interactive Topic Modeling Analysis",
                'x': 0.5,
                'font': {'size': 16}
            },
            height=800,
            showlegend=True
        )
        
        # Update axis labels
        fig.update_xaxes(title_text="Topic Number", row=1, col=1)
        fig.update_yaxes(title_text="Instance Count", row=1, col=1)
        
        fig.update_xaxes(title_text="Sentiment Polarity", row=1, col=2)
        fig.update_yaxes(title_text="Pre/Post Ratio", row=1, col=2)
        
        fig.update_xaxes(title_text="Top Words", row=2, col=1)
        fig.update_yaxes(title_text="Frequency", row=2, col=1)
        
        fig.update_xaxes(title_text="Topic Number", row=2, col=2)
        fig.update_yaxes(title_text="Average Sentiment", row=2, col=2)
        
        self.figures['topic_modeling'] = fig
        print("Topic modeling visualization created successfully")
        return fig
    
    def create_bee_swarm_plots(self):
        """
        Create interactive bee swarm plots for token distribution analysis.
        """
        print("\nCREATING BEE SWARM PLOTS")
        print("-" * 25)
        
        # Filter valid token data
        token_df = self.df[
            (self.df['Pre_Comparator_Tokens'].notna()) & 
            (self.df['Post_Comparator_Tokens'].notna())
        ].copy()
        
        # Create subplot figure
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'Pre-Comparator Token Distribution',
                'Post-Comparator Token Distribution', 
                'Pre/Post Ratio Distribution',
                'Total Token Length Distribution'
            )
        )
        
        colors = {'manual': '#FF6B6B', 'computational': '#4ECDC4', 'bnc': '#45B7D1'}
        
        # 1. Pre-comparator tokens
        for dataset in token_df['Dataset'].unique():
            dataset_data = token_df[token_df['Dataset'] == dataset]
            
            fig.add_trace(
                go.Box(
                    y=dataset_data['Pre_Comparator_Tokens'],
                    name=f"{dataset.title()}",
                    boxpoints='all',
                    pointpos=0,
                    marker=dict(color=colors.get(dataset, '#666666')),
                    hovertemplate="<b>%{fullData.name}</b><br>" +
                                 "Pre-tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=1, col=1
            )
        
        # 2. Post-comparator tokens
        for dataset in token_df['Dataset'].unique():
            dataset_data = token_df[token_df['Dataset'] == dataset]
            
            fig.add_trace(
                go.Box(
                    y=dataset_data['Post_Comparator_Tokens'],
                    name=f"{dataset.title()}",
                    boxpoints='all',
                    pointpos=0,
                    marker=dict(color=colors.get(dataset, '#666666')),
                    showlegend=False,
                    hovertemplate="<b>%{fullData.name}</b><br>" +
                                 "Post-tokens: %{y}<br>" +
                                 "<extra></extra>"
                ),
                row=1, col=2
            )
        
        # 3. Pre/Post ratio
        for dataset in token_df['Dataset'].unique():
            dataset_data = token_df[token_df['Dataset'] == dataset]
            valid_ratios = dataset_data[dataset_data['Pre_Post_Ratio'].notna()]
            
            if len(valid_ratios) > 0:
                fig.add_trace(
                    go.Box(
                        y=valid_ratios['Pre_Post_Ratio'],
                        name=f"{dataset.title()}",
                        boxpoints='all',
                        pointpos=0,
                        marker=dict(color=colors.get(dataset, '#666666')),
                        showlegend=False,
                        hovertemplate="<b>%{fullData.name}</b><br>" +
                                     "Ratio: %{y:.2f}<br>" +
                                     "<extra></extra>"
                    ),
                    row=2, col=1
                )
        
        # 4. Total tokens
        for dataset in token_df['Dataset'].unique():
            dataset_data = token_df[token_df['Dataset'] == dataset]
            
            if 'Total_Tokens' in dataset_data.columns:
                valid_totals = dataset_data[dataset_data['Total_Tokens'].notna()]
                
                if len(valid_totals) > 0:
                    fig.add_trace(
                        go.Box(
                            y=valid_totals['Total_Tokens'],
                            name=f"{dataset.title()}",
                            boxpoints='all',
                            pointpos=0,
                            marker=dict(color=colors.get(dataset, '#666666')),
                            showlegend=False,
                            hovertemplate="<b>%{fullData.name}</b><br>" +
                                         "Total tokens: %{y}<br>" +
                                         "<extra></extra>"
                        ),
                        row=2, col=2
                    )
        
        # Update layout
        fig.update_layout(
            title={
                'text': "Token Distribution Analysis: Joyce vs BNC Patterns",
                'x': 0.5,
                'font': {'size': 16}
            },
            height=800,
            showlegend=True
        )
        
        # Update axis labels
        fig.update_yaxes(title_text="Token Count", row=1, col=1)
        fig.update_yaxes(title_text="Token Count", row=1, col=2)
        fig.update_yaxes(title_text="Ratio", row=2, col=1)
        fig.update_yaxes(title_text="Token Count", row=2, col=2)
        
        self.figures['bee_swarm'] = fig
        print("Bee swarm plots created successfully")
        return fig
    
    def create_comprehensive_heatmap(self):
        """
        Create comprehensive multi-dimensional heatmap for pattern analysis.
        """
        print("\nCREATING COMPREHENSIVE HEATMAP")
        print("-" * 32)
        
        # Prepare data for heatmap
        numeric_columns = [
            'Pre_Comparator_Tokens', 'Post_Comparator_Tokens', 'Pre_Post_Ratio',
            'Total_Tokens', 'Sentiment_Polarity', 'Sentiment_Subjectivity',
            'Syntactic_Complexity'
        ]
        
        # Filter to valid numeric data
        heatmap_df = self.df[['Dataset', 'Category_Framework'] + numeric_columns].copy()
        heatmap_df = heatmap_df.dropna()
        
        if len(heatmap_df) == 0:
            print("No valid numeric data for heatmap")
            return None
        
        # Calculate mean values by dataset and category
        pivot_data = heatmap_df.groupby(['Dataset', 'Category_Framework']).mean().reset_index()
        
        # Create heatmap matrix
        heatmap_matrix = []
        row_labels = []
        
        for dataset in pivot_data['Dataset'].unique():
            for category in pivot_data['Category_Framework'].unique():
                subset = pivot_data[
                    (pivot_data['Dataset'] == dataset) & 
                    (pivot_data['Category_Framework'] == category)
                ]
                
                if len(subset) > 0:
                    values = subset[numeric_columns].iloc[0].values
                    heatmap_matrix.append(values)
                    row_labels.append(f"{dataset}_{category}")
        
        if len(heatmap_matrix) == 0:
            print("No data available for heatmap matrix")
            return None
        
        heatmap_matrix = np.array(heatmap_matrix)
        
        # Normalize data for better visualization
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        heatmap_normalized = scaler.fit_transform(heatmap_matrix)
        
        # Create interactive heatmap
        fig = go.Figure(data=go.Heatmap(
            z=heatmap_normalized,
            x=[col.replace('_', ' ').title() for col in numeric_columns],
            y=row_labels,
            colorscale='RdYlBu_r',
            hovertemplate="<b>%{y}</b><br>" +
                         "%{x}: %{z:.2f}<br>" +
                         "<extra></extra>",
            colorbar=dict(title="Normalized Values")
        ))
        
        fig.update_layout(
            title={
                'text': "Multi-Dimensional Heatmap: Linguistic Features by Dataset & Category",
                'x': 0.5,
                'font': {'size': 16}
            },
            xaxis_title="Linguistic Features",
            yaxis_title="Dataset_Category Combinations",
            height=600
        )
        
        self.figures['heatmap'] = fig
        print("Comprehensive heatmap created successfully")
        return fig
    
    def create_joyce_vs_bnc_comparison(self):
        """
        Create specialized visualization comparing Joyce patterns vs BNC baseline.
        """
        print("\nCREATING JOYCE VS BNC COMPARISON")
        print("-" * 34)
        
        # Separate Joyce data (manual + computational) from BNC
        joyce_data = self.df[self.df['Dataset'].isin(['manual', 'computational'])].copy()
        bnc_data = self.df[self.df['Dataset'] == 'bnc'].copy()
        
        # Create comparison figure with multiple subplots
        fig = make_subplots(
            rows=3, cols=2,
            subplot_titles=(
                'Category Distribution Comparison',
                'Structural Pattern Comparison',
                'Sentiment Pattern Comparison', 
                'Comparator Usage Comparison',
                'Token Length Distribution',
                'Statistical Significance Test'
            ),
            specs=[[{"type": "bar"}, {"type": "scatter"}],
                   [{"type": "violin"}, {"type": "bar"}],
                   [{"type": "box"}, {"type": "table"}]]
        )
        
        # 1. Category distribution comparison
        joyce_cats = joyce_data['Category_Framework'].value_counts(normalize=True)
        bnc_cats = bnc_data['Category_Framework'].value_counts(normalize=True)
        
        all_categories = sorted(set(joyce_cats.index) | set(bnc_cats.index))
        
        joyce_props = [joyce_cats.get(cat, 0) for cat in all_categories]
        bnc_props = [bnc_cats.get(cat, 0) for cat in all_categories]
        
        fig.add_trace(
            go.Bar(
                x=all_categories,
                y=joyce_props,
                name="Joyce",
                marker_color='#FF6B6B',
                hovertemplate="<b>Joyce</b><br>" +
                             "Category: %{x}<br>" +
                             "Proportion: %{y:.3f}<br>" +
                             "<extra></extra>"
            ),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Bar(
                x=all_categories,
                y=bnc_props,
                name="BNC",
                marker_color='#45B7D1',
                hovertemplate="<b>BNC</b><br>" +
                             "Category: %{x}<br>" +
                             "Proportion: %{y:.3f}<br>" +
                             "<extra></extra>"
            ),
            row=1, col=1
        )
