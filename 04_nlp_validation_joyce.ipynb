{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOUR_USERNAME/nlp-tagging-validation-joyce/blob/main/04_nlp_validation_joyce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# NLP Tagging Validation for Joyce's Dubliners\n",
        "\n",
        "This notebook validates modern NLP POS tagging tools against expert CLAWS7 annotations for simile sentences from James Joyce's *Dubliners*.\n",
        "\n",
        "## Research Objectives\n",
        "- Compare accuracy of spaCy, NLTK, Flair, Stanza, TextBlob against CLAWS7 annotations\n",
        "- Identify systematic tagging errors in literary text processing\n",
        "- Analyze Joyce-specific linguistic challenges for computational tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Install and setup NLP libraries\n",
        "print(\"ðŸ”§ Installing NLP libraries...\")\n",
        "!pip install -q spacy nltk flair stanza textblob scikit-learn plotly seaborn wordcloud\n",
        "\n",
        "print(\"ðŸ“¥ Downloading spaCy models...\")\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "print(\"ðŸ“š Downloading NLTK data...\")\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "print(\"âœ… Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# NLP libraries\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from textblob import TextBlob\n",
        "import stanza\n",
        "\n",
        "# Analysis libraries\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOUR_USERNAME/nlp-tagging-validation-joyce/blob/main/nlp_validation_joyce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# NLP Tagging Validation for Joyce's Dubliners\n",
        "\n",
        "This notebook validates modern NLP POS tagging tools against expert CLAWS7 annotations for simile sentences from James Joyce's *Dubliners*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Install and setup\n",
        "!pip install spacy nltk flair stanza textblob scikit-learn plotly seaborn\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from textblob import TextBlob\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_data"
      },
      "outputs": [],
      "source": [
        "# Upload your CSV file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the data\n",
        "csv_filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(csv_filename)\n",
        "\n",
        "print(f\"Loaded {len(df)} rows\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_data"
      },
      "outputs": [],
      "source": [
        "# Process CLAWS data\n",
        "def parse_claws_tags(claws_string):\n",
        "    \"\"\"Parse CLAWS7 format: 'word_TAG word_TAG ...'\"\"\"\n",
        "    if pd.isna(claws_string):\n",
        "        return [], []\n",
        "    \n",
        "    tokens = []\n",
        "    tags = []\n",
        "    \n",
        "    for item in claws_string.strip().split():\n",
        "        if '_' in item:\n",
        "            parts = item.rsplit('_', 1)\n",
        "            if len(parts) == 2:\n",
        "                word, tag = parts\n",
        "                tokens.append(word)\n",
        "                tags.append(tag)\n",
        "    \n",
        "    return tokens, tags\n",
        "\n",
        "# Process all sentences\n",
        "processed_data = []\n",
        "clean_df = df[['Sentences', 'CLAWS']].dropna()\n",
        "\n",
        "for idx, row in clean_df.iterrows():\n",
        "    tokens, tags = parse_claws_tags(row['CLAWS'])\n",
        "    if tokens and tags:\n",
        "        processed_data.append({\n",
        "            'sentence': row['Sentences'],\n",
        "            'tokens': tokens,\n",
        "            'ground_truth_tags': tags\n",
        "        })\n",
        "\n",
        "print(f\"Processed {len(processed_data)} valid sentences\")\n",
        "print(f\"Sample: {processed_data[0]['sentence'][:80]}...\")\n",
        "print(f\"Tags: {processed_data[0]['ground_truth_tags'][:5]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlp_tools"
      },
      "outputs": [],
      "source": [
        "# Initialize NLP tools\n",
        "print(\"Loading NLP models...\")\n",
        "\n",
        "# Load models\n",
        "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
        "nlp_lg = spacy.load(\"en_core_web_lg\")\n",
        "flair_tagger = SequenceTagger.load('pos')\n",
        "\n",
        "print(\"NLP tools ready!\")"
      ]
    }
  ]
}
